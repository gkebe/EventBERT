Convert XLNet model to huggingface
    export TRANSFO_XL_CHECKPOINT_PATH=~/Nvidia-Bert/model/xlnet/200000/model.ckpt
    export TRANSFO_XL_CONFIG_PATH=~/Nvidia-Bert/xlnet_config.json
    export PYTORCH_DUMP_OUTPUT=~/Nvidia-Bert/model/xlnet/200000

    transformers-cli convert --model_type xlnet --tf_checkpoint $TRANSFO_XL_CHECKPOINT_PATH --config $TRANSFO_XL_CONFIG_PATH --pytorch_dump_output $PYTORCH_DUMP_OUTPUT
GPT-2 data preocessing:
    python data/eventPrep.py --input_file data/wiki_70k/step1/train.txt --output_file data/wiki_70k/step2/train_gpt2.txt  --add_tup True
    awk '{filename = "data/wiki_70k/step3/wiki_70k_gpt2_training_" int((NR-1)/80000) ".txt"; print >> filename}' data/wiki_70k/step2/train_gpt2.txt

Pretraining GPT-2 model
    python data_utils.py --bsz_per_host=1 --num_core_per_host=1 --seq_len=512 --reuse_len=256 --input_glob=data/wiki_70k/step3/wiki_70k_training*.txt --save_dir=output_data --num_passes=20 --bi_data=True --sp_path=spiece.model --mask_alpha=6 --mask_beta=1 --num_predict=85 --uncased=False
    python train.py --dataset="OUT.npz" --batch_size=10

Convert GPT-2 model to huggingface
    export OPENAI_GPT2_CHECKPOINT_PATH=~/Nvidia-Bert/model/gpt2/348000
    export PYTORCH_DUMP_OUTPUT=~/Nvidia-Bert/model/gpt2/348000

    transformers-cli convert --model_type gpt2 --tf_checkpoint OPENAI_GPT2_CHECKPOINT_PATH --pytorch_dump_output $PYTORCH_DUMP_OUTPUT

Generate events with XLNet
    python run_generation.py --model_type xlnet --model_name xlnet-base-cased --model_name_or_path model/xlnet/pytorch_model.bin --num_return_sequences 10 --no_tokenizer

Generate events with GPT-2
    python run_generation.py --model_type gpt2 --model_name gpt2 --model_name_or_path model/gpt2/348000/ --num_return_sequences 10

Inverse Cloze with Bert
    bash scripts/run_inverse_cloze.sh -c checkpoints/bert-base.pt -i cloze_dataset_weber_test.json -g "2"

Inverse Cloze with XLNet
    bash scripts/run_inverse_cloze_xlnet.sh -c model/xlnet/200000/pytorch_model.bin -i cloze_dataset_weber.json -g "2"

Inverse Cloze with GPT-2
    bash scripts/run_inverse_cloze_gpt2.sh -c model/gpt2/200000/pytorch_model.bin -i cloze_dataset_weber.json -g "2"